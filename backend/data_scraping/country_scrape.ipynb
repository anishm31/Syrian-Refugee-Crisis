{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Description: Scrape UNHCR API for data on Syrian refugees in a specific countries of asylum\n",
    "##### Author: Matthew Albert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necesssary packages and modules\n",
    "import requests\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "from dateutil.parser import isoparse\n",
    "from maps_utilities import get_map_info\n",
    "from wikidata_utilities import get_page_data, get_page_id, get_page_title, get_img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define specific parameters for the scrape\n",
    "\n",
    "syria_iso = \"SYR\"                              # ISO code for Syria (country of origin)\n",
    "endpoints = [\"population\", \"asylum-decisions\"] # API endpoints to scrape\n",
    "num_instances = 50                             # Num items to return\n",
    "year_from = 2010                               # Fetch results starting from this year (inclusive)\n",
    "year_to = 2023                                 # Fetch results ending at this year (inclusive)\n",
    "\n",
    "json_file_path = \"./models_data/country_db.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define JSON structure that will be used to store the scraped data\n",
    "country_instance = {\n",
    "  \"country_name\" : \"\",\n",
    "  \"id\" : \"\",\n",
    "  \"attributes\" : {\n",
    "    \"country_iso3\" : \"\",\n",
    "    \"flag_url\" : \"\",\n",
    "    \"map_info\" : \"\",\n",
    "    \"capital\" : \"\",\n",
    "    \"num_refugees\" : 0,\n",
    "    \"num_asylum_decisions\" : 0,\n",
    "    \"year_of_decisions\" : 0,\n",
    "    \"num_recognized\" : 0,\n",
    "    \"num_other\" : 0,\n",
    "    \"num_apps_rejected\" : 0,\n",
    "    \"num_closed\" : 0\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous functions\n",
    "\n",
    "# Extract the current capital(s) of a country from a list of previous capital cities\n",
    "def extract_curr_capital(capital_data):\n",
    "  # Store capitals in set to avoid duplicates\n",
    "  capitals = set()\n",
    "  if len(capital_data) == 1:\n",
    "    # Return, only one capital city in list\n",
    "    capitals.add(get_page_title(capital_data[0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]))\n",
    "    return list(capitals)\n",
    "  for capital_entry in capital_data:\n",
    "    # Store property ID for the \"end time\" field\n",
    "    end_time_property = \"P582\"\n",
    "    if end_time_property not in capital_entry[\"qualifiers\"]:\n",
    "      # This is a current capital city, add to list\n",
    "      capitals.add(get_page_title(capital_entry[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]))\n",
    "  return list(capitals)\n",
    "\n",
    "# Extract the current flag of a country from a list of previous flags\n",
    "def extract_curr_flag(flag_data):\n",
    "  if (len(flag_data) == 1):\n",
    "    # Only one flag in list, return\n",
    "    return flag_data[0][\"mainsnak\"][\"datavalue\"][\"value\"]\n",
    "  # Try to sort list of json objects by the \"start time\" field (P580)\n",
    "  start_time = \"P580\"\n",
    "  try:\n",
    "    # Sort objects by ISO 8601 formatted dates\n",
    "    sorted_flag_data = sorted(flag_data, key = lambda i: isoparse(i[\"qualifiers\"][start_time][0][\"datavalue\"][\"value\"][\"time\"][1:]), reverse=True)\n",
    "    # Return flag at front of list (most recent flag)\n",
    "    return sorted_flag_data[0][\"mainsnak\"][\"datavalue\"][\"value\"]\n",
    "  except:\n",
    "    # Failed to sort list, most likely problem with data format, return first flag in list\n",
    "    return flag_data[0][\"mainsnak\"][\"datavalue\"][\"value\"]\n",
    "\n",
    "# Function to scrape country data that is only available through Wikidata API\n",
    "def get_wikidata_fields(country_name, country_data):\n",
    "  # Retrieve page ID of country page\n",
    "  page_id = get_page_id(country_name)\n",
    "  # Retrieve Wikidata data for country page\n",
    "  json_response = get_page_data(page_id)\n",
    "  # Attempt to scrape capital city data\n",
    "  try:\n",
    "    capital_property = \"P36\"\n",
    "    # Extract property info from JSON response\n",
    "    capital_entries = json_response[\"entities\"][page_id][\"claims\"][capital_property]\n",
    "    capitals = extract_curr_capital(capital_entries)\n",
    "    # Store list with capital city (or cities)\n",
    "    country_data[\"attributes\"][\"capital\"] = capitals\n",
    "  except:\n",
    "    print(f\"Failed to retrieve capital city data for {country_name}\")\n",
    "  # Attempt to scrape country flag image url\n",
    "  try:\n",
    "    flag_property = \"P41\"\n",
    "    # Get image file name from page data\n",
    "    file_name = extract_curr_flag(json_response[\"entities\"][page_id][\"claims\"][flag_property])\n",
    "    # Get image URL from file name\n",
    "    img_url = get_img_url(file_name)\n",
    "    # Store image URL in instance data\n",
    "    country_data[\"attributes\"][\"flag_url\"] = img_url\n",
    "  except:\n",
    "    print(f\"Failed to retrieve flag image url for {country_name}\")\n",
    "    \n",
    "# Function to select the index with the most recent and populous asylum decisions data\n",
    "def filter_asylum_data(asylum_data):\n",
    "  selected_index = -1\n",
    "  # Store the most recent year (that is available)\n",
    "  recent_year = asylum_data[-1][\"year\"]\n",
    "  # Since most recent data is stored at end of list, iterate in reverse\n",
    "  for i in range(len(asylum_data) - 1, -1, -1):\n",
    "    if asylum_data[i][\"year\"] == recent_year:\n",
    "      # Store index if this item contains more asylum decisions than the previously stored one\n",
    "      if asylum_data[i][\"dec_total\"] > asylum_data[selected_index][\"dec_total\"]:\n",
    "        selected_index = i\n",
    "    else:\n",
    "      # No more items with the most recent year, exit loop\n",
    "      break\n",
    "  return selected_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape data for a single country (using a country's ISO3 code)\n",
    "def scrape_country_data(country_code):\n",
    "  # Retrieve deep copy of country_instance dict to store country data\n",
    "  data = copy.deepcopy(country_instance)\n",
    "  data[\"id\"] = data[\"attributes\"][\"country_iso3\"] = country_code\n",
    "  # Iterate through each endpoint to scrape necessary attributes\n",
    "  for endpoint in endpoints:\n",
    "    params = {\n",
    "      \"limit\" : num_instances,\n",
    "      \"yearFrom\" : year_from,\n",
    "      \"yearTo\" : year_to,\n",
    "      \"coo\" : syria_iso,\n",
    "      \"coa\" : country_code,\n",
    "      \"cf_type\" : \"ISO\"       # Search for countries using ISO3 country codes\n",
    "    }\n",
    "    # Make request to UNHCR API\n",
    "    response = requests.get(f\"https://api.unhcr.org/population/v1/{endpoint}/\", params=params)\n",
    "    if response.status_code == 200:\n",
    "      # Success, store data in json format\n",
    "      response_data = response.json()\n",
    "      if len(response_data[\"items\"]) == 0:\n",
    "        # No data available for this country, skip country\n",
    "        return None\n",
    "      if endpoint == \"population\":\n",
    "        # Select item at end of list (b/c it is the most recent year)\n",
    "        item_index = -1\n",
    "        # Store population dataset specific attribute\n",
    "        data[\"attributes\"][\"num_refugees\"] = response_data[\"items\"][item_index][\"refugees\"]\n",
    "        data[\"country_name\"] = response_data[\"items\"][item_index][\"coa_name\"]\n",
    "      else:\n",
    "        # Select data item with most recent year and most asylum decisions\n",
    "        item_index = filter_asylum_data(response_data[\"items\"])\n",
    "        # Store asylum decisions dataset specific attributes\n",
    "        data[\"attributes\"][\"num_asylum_decisions\"] = response_data[\"items\"][item_index][\"dec_total\"]\n",
    "        data[\"attributes\"][\"year_of_decisions\"] = response_data[\"items\"][item_index][\"year\"]\n",
    "        data[\"attributes\"][\"num_recognized\"] = response_data[\"items\"][item_index][\"dec_recognized\"]\n",
    "        data[\"attributes\"][\"num_apps_rejected\"] = response_data[\"items\"][item_index][\"dec_rejected\"]\n",
    "        data[\"attributes\"][\"num_other\"] = response_data[\"items\"][item_index][\"dec_other\"]\n",
    "        data[\"attributes\"][\"num_closed\"] = response_data[\"items\"][item_index][\"dec_closed\"]\n",
    "    else:\n",
    "      # Error, print status code\n",
    "      print(f\"Request Error: {response.status_code}\")\n",
    "      print(f\"Request URL: {response.url}\")\n",
    "      print(f\"Country: {country_code}\")\n",
    "      exit(-1)\n",
    "  # Scrape remaining data fields (flag image url, capital city (or cities), map info)\n",
    "  data[\"attributes\"][\"map_info\"] = get_map_info(data[\"country_name\"])\n",
    "  get_wikidata_fields(data[\"country_name\"], data)\n",
    "  return data\n",
    "\n",
    "# Function to scrape the name and ISO3 code for all countries in UNHCR database\n",
    "def get_all_countries():\n",
    "  countries = []\n",
    "  # Set request parameters\n",
    "  params = {\n",
    "    \"limit\" : 600\n",
    "  }\n",
    "  # Make request to UNHCR API\n",
    "  response = requests.get(\"https://api.unhcr.org/population/v1/countries/\", params=params)\n",
    "  if response.status_code == 200:\n",
    "    # Success, store data in json format\n",
    "    response_data = response.json()\n",
    "    # Parse and store country name and ISO3 code for each country\n",
    "    for country in response_data[\"items\"]:\n",
    "      countries.append({\n",
    "        \"name\" : country[\"name\"],\n",
    "        \"iso3\" : country[\"iso\"]\n",
    "      })\n",
    "  else:\n",
    "    # Error, print status code\n",
    "    print(f\"Request Error: {response.status_code}\")\n",
    "    print(f\"Request URL: {response.url}\")\n",
    "    exit(-1)\n",
    "  return countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Afghanistan...1/230\n",
      "Scraping data for Albania...2/230\n",
      "Scraping data for Algeria...3/230\n",
      "Scraping data for Andorra...4/230\n",
      "Scraping data for Angola...5/230\n",
      "Scraping data for Anguilla...6/230\n",
      "Scraping data for Antigua and Barbuda...7/230\n",
      "Scraping data for Argentina...8/230\n",
      "Scraping data for Armenia...9/230\n",
      "Scraping data for Aruba...10/230\n",
      "Scraping data for Australia...11/230\n",
      "Scraping data for Austria...12/230\n",
      "Scraping data for Azerbaijan...13/230\n",
      "Scraping data for Bahamas...14/230\n",
      "Scraping data for Bahrain...15/230\n",
      "Scraping data for Bangladesh...16/230\n",
      "Scraping data for Barbados...17/230\n",
      "Scraping data for Belarus...18/230\n",
      "Scraping data for Belgium...19/230\n",
      "Scraping data for Belize...20/230\n",
      "Scraping data for Benin...21/230\n",
      "Failed to retrieve capital city data for Benin\n",
      "Scraping data for Bermuda...22/230\n",
      "Scraping data for Bhutan...23/230\n",
      "Scraping data for Bolivia (Plurinational State of)...24/230\n",
      "Scraping data for Bonaire, Saint Eustatius and Saba...25/230\n",
      "Scraping data for Bosnia and Herzegovina...26/230\n",
      "Scraping data for Botswana...27/230\n",
      "Scraping data for Bouvet Island...28/230\n",
      "Scraping data for Brazil...29/230\n",
      "Scraping data for British Virgin Islands...30/230\n",
      "Scraping data for Brunei Darussalam...31/230\n",
      "Scraping data for Bulgaria...32/230\n",
      "Scraping data for Burkina Faso...33/230\n",
      "Scraping data for Burundi...34/230\n",
      "Scraping data for Cabo Verde...35/230\n",
      "Scraping data for Cambodia...36/230\n",
      "Scraping data for Cameroon...37/230\n",
      "Scraping data for Canada...38/230\n",
      "Scraping data for Cayman Islands...39/230\n",
      "Scraping data for Central African Rep....40/230\n",
      "Request for page ID failed\n",
      "Failed to retrieve capital city data for Central African Rep.\n",
      "Failed to retrieve flag image url for Central African Rep.\n",
      "Scraping data for Chad...41/230\n",
      "Scraping data for Chile...42/230\n",
      "Scraping data for China...43/230\n",
      "Scraping data for China, Hong Kong SAR...44/230\n",
      "Scraping data for China, Macao SAR...45/230\n",
      "Request for page ID failed\n",
      "Failed to retrieve capital city data for China, Macao SAR\n",
      "Failed to retrieve flag image url for China, Macao SAR\n",
      "Scraping data for Colombia...46/230\n",
      "Scraping data for Comoros...47/230\n",
      "Scraping data for Congo...48/230\n",
      "Scraping data for Cook Islands...49/230\n",
      "Scraping data for Costa Rica...50/230\n",
      "Scraping data for Cote d'Ivoire...51/230\n",
      "Scraping data for Croatia...52/230\n",
      "Scraping data for Cuba...53/230\n",
      "Scraping data for Curacao ...54/230\n",
      "Scraping data for Cyprus...55/230\n",
      "Scraping data for Czechia...56/230\n",
      "Scraping data for Dem. People's Rep. of Korea...57/230\n",
      "Scraping data for Dem. Rep. of the Congo...58/230\n",
      "Request for page ID failed\n",
      "Failed to retrieve capital city data for Dem. Rep. of the Congo\n",
      "Failed to retrieve flag image url for Dem. Rep. of the Congo\n",
      "Scraping data for Denmark...59/230\n",
      "Scraping data for Djibouti...60/230\n",
      "Scraping data for Dominica...61/230\n",
      "Scraping data for Dominican Rep....62/230\n",
      "Request for page ID failed\n",
      "Failed to retrieve capital city data for Dominican Rep.\n",
      "Failed to retrieve flag image url for Dominican Rep.\n",
      "Scraping data for Ecuador...63/230\n",
      "Scraping data for Egypt...64/230\n",
      "Failed to retrieve capital city data for Egypt\n",
      "Scraping data for El Salvador...65/230\n",
      "Scraping data for Equatorial Guinea...66/230\n",
      "Scraping data for Eritrea...67/230\n",
      "Scraping data for Estonia...68/230\n",
      "Scraping data for Eswatini...69/230\n",
      "Scraping data for Ethiopia...70/230\n",
      "Scraping data for Faeroe Islands...71/230\n",
      "Scraping data for Fiji...72/230\n",
      "Scraping data for Finland...73/230\n",
      "Scraping data for France...74/230\n",
      "Scraping data for French Guiana...75/230\n",
      "Scraping data for French Polynesia...76/230\n",
      "Scraping data for Gabon...77/230\n",
      "Scraping data for Gambia...78/230\n",
      "Scraping data for Georgia...79/230\n",
      "Scraping data for Germany...80/230\n",
      "Scraping data for Ghana...81/230\n",
      "Scraping data for Gibraltar...82/230\n",
      "Scraping data for Greece...83/230\n",
      "Scraping data for Greenland...84/230\n",
      "Scraping data for Grenada...85/230\n",
      "Scraping data for Guadeloupe...86/230\n",
      "Scraping data for Guam...87/230\n",
      "Scraping data for Guatemala...88/230\n",
      "Scraping data for Guinea...89/230\n",
      "Scraping data for Guinea-Bissau...90/230\n",
      "Scraping data for Guyana...91/230\n",
      "Scraping data for Haiti...92/230\n",
      "Scraping data for Holy See...93/230\n",
      "Scraping data for Honduras...94/230\n",
      "Scraping data for Hungary...95/230\n",
      "Scraping data for Iceland...96/230\n",
      "Scraping data for India...97/230\n",
      "Scraping data for Indonesia...98/230\n",
      "Scraping data for Iran (Islamic Rep. of)...99/230\n",
      "Scraping data for Iraq...100/230\n",
      "Scraping data for Ireland...101/230\n",
      "Scraping data for Israel...102/230\n",
      "Scraping data for Italy...103/230\n",
      "Scraping data for Jamaica...104/230\n",
      "Scraping data for Japan...105/230\n",
      "Scraping data for Jordan...106/230\n",
      "Map Info Scraping Error: Country = Jordan, Error Code = 200\n",
      "API Reponse: {'results': [], 'status': 'ZERO_RESULTS'}\n",
      "Scraping data for Kazakhstan...107/230\n",
      "Scraping data for Kenya...108/230\n",
      "Scraping data for Kiribati...109/230\n",
      "Scraping data for Kuwait...110/230\n",
      "Scraping data for Kyrgyzstan...111/230\n",
      "Scraping data for Lao People's Dem. Rep....112/230\n",
      "Scraping data for Latvia...113/230\n",
      "Scraping data for Lebanon...114/230\n",
      "Scraping data for Lesotho...115/230\n",
      "Scraping data for Liberia...116/230\n",
      "Scraping data for Libya...117/230\n",
      "Scraping data for Liechtenstein...118/230\n",
      "Scraping data for Lithuania...119/230\n",
      "Failed to retrieve capital city data for Lithuania\n",
      "Scraping data for Luxembourg...120/230\n",
      "Scraping data for Madagascar...121/230\n",
      "Scraping data for Malawi...122/230\n",
      "Scraping data for Malaysia...123/230\n",
      "Scraping data for Maldives...124/230\n",
      "Scraping data for Mali...125/230\n",
      "Scraping data for Malta...126/230\n",
      "Scraping data for Marshall Islands...127/230\n",
      "Scraping data for Martinique...128/230\n",
      "Scraping data for Mauritania...129/230\n",
      "Scraping data for Mauritius...130/230\n",
      "Scraping data for Mexico...131/230\n",
      "Scraping data for Micronesia (Federated States of)...132/230\n",
      "Scraping data for Monaco...133/230\n",
      "Scraping data for Mongolia...134/230\n",
      "Scraping data for Montenegro...135/230\n",
      "Scraping data for Montserrat...136/230\n",
      "Scraping data for Morocco...137/230\n",
      "Scraping data for Mozambique...138/230\n",
      "Scraping data for Myanmar...139/230\n",
      "Scraping data for Namibia...140/230\n",
      "Scraping data for Nauru...141/230\n",
      "Scraping data for Nepal...142/230\n",
      "Scraping data for Netherlands (Kingdom of the)...143/230\n",
      "Request for page ID failed\n",
      "Failed to retrieve capital city data for Netherlands (Kingdom of the)\n",
      "Failed to retrieve flag image url for Netherlands (Kingdom of the)\n",
      "Scraping data for New Caledonia...144/230\n",
      "Scraping data for New Zealand...145/230\n",
      "Scraping data for Nicaragua...146/230\n",
      "Scraping data for Niger...147/230\n",
      "Scraping data for Nigeria...148/230\n",
      "Scraping data for Niue...149/230\n",
      "Scraping data for North Macedonia...150/230\n",
      "Scraping data for Northern Mariana Islands...151/230\n",
      "Scraping data for Norway...152/230\n",
      "Scraping data for Oman...153/230\n",
      "Scraping data for Pakistan...154/230\n",
      "Scraping data for Palau...155/230\n",
      "Scraping data for Panama...156/230\n",
      "Scraping data for Papua New Guinea...157/230\n",
      "Scraping data for Paraguay...158/230\n",
      "Scraping data for Peru...159/230\n",
      "Scraping data for Philippines...160/230\n",
      "Scraping data for Poland...161/230\n",
      "Scraping data for Portugal...162/230\n",
      "Scraping data for Puerto Rico...163/230\n",
      "Scraping data for Qatar...164/230\n",
      "Scraping data for Rep. of Korea...165/230\n",
      "Request for page ID failed\n",
      "Failed to retrieve capital city data for Rep. of Korea\n",
      "Failed to retrieve flag image url for Rep. of Korea\n",
      "Scraping data for Rep. of Moldova...166/230\n",
      "Request for page ID failed\n",
      "Failed to retrieve capital city data for Rep. of Moldova\n",
      "Failed to retrieve flag image url for Rep. of Moldova\n",
      "Scraping data for Reunion...167/230\n",
      "Scraping data for Romania...168/230\n",
      "Scraping data for Russian Federation...169/230\n",
      "Scraping data for Rwanda...170/230\n",
      "Scraping data for Saint Kitts and Nevis...171/230\n",
      "Scraping data for Saint Lucia...172/230\n",
      "Scraping data for Saint Vincent and the Grenadines...173/230\n",
      "Scraping data for Saint-Martin (French part)...174/230\n",
      "Scraping data for Saint-Pierre-et-Miquelon...175/230\n",
      "Scraping data for Samoa...176/230\n",
      "Scraping data for San Marino...177/230\n",
      "Scraping data for Sao Tome and Principe...178/230\n",
      "Scraping data for Saudi Arabia...179/230\n",
      "Scraping data for Senegal...180/230\n",
      "Scraping data for Serbia and Kosovo: S/RES/1244 (1999)...181/230\n",
      "Request for page ID failed\n",
      "Failed to retrieve capital city data for Serbia and Kosovo: S/RES/1244 (1999)\n",
      "Failed to retrieve flag image url for Serbia and Kosovo: S/RES/1244 (1999)\n",
      "Scraping data for Seychelles...182/230\n",
      "Scraping data for Sierra Leone...183/230\n",
      "Scraping data for Singapore...184/230\n",
      "Scraping data for Sint Maarten (Dutch part)...185/230\n",
      "Scraping data for Slovakia...186/230\n",
      "Scraping data for Slovenia...187/230\n",
      "Scraping data for Solomon Islands...188/230\n",
      "Scraping data for Somalia...189/230\n",
      "Scraping data for South Africa...190/230\n",
      "Scraping data for South Georgia and the South Sandwich Islands...191/230\n",
      "Scraping data for South Sudan...192/230\n",
      "Scraping data for Spain...193/230\n",
      "Scraping data for Sri Lanka...194/230\n",
      "Scraping data for State of Palestine...195/230\n",
      "Scraping data for Stateless...196/230\n",
      "Scraping data for Sudan...197/230\n",
      "Scraping data for Suriname...198/230\n",
      "Scraping data for Svalbard and Jan Mayen...199/230\n",
      "Scraping data for Sweden...200/230\n",
      "Scraping data for Switzerland...201/230\n",
      "Failed to retrieve capital city data for Switzerland\n",
      "Scraping data for Syrian Arab Rep....202/230\n",
      "Scraping data for Tajikistan...203/230\n",
      "Scraping data for Thailand...204/230\n",
      "Scraping data for Tibetan...205/230\n",
      "Scraping data for Timor-Leste...206/230\n",
      "Scraping data for Togo...207/230\n",
      "Scraping data for Tonga...208/230\n",
      "Scraping data for Trinidad and Tobago...209/230\n",
      "Scraping data for Tunisia...210/230\n",
      "Scraping data for TÃ¼rkiye...211/230\n",
      "Scraping data for Turkmenistan...212/230\n",
      "Scraping data for Turks and Caicos Islands...213/230\n",
      "Scraping data for Tuvalu...214/230\n",
      "Scraping data for Uganda...215/230\n",
      "Scraping data for Ukraine...216/230\n",
      "Scraping data for United Arab Emirates...217/230\n",
      "Scraping data for United Kingdom of Great Britain and Northern Ireland...218/230\n",
      "Scraping data for United Rep. of Tanzania...219/230\n",
      "Request for page ID failed\n",
      "Failed to retrieve capital city data for United Rep. of Tanzania\n",
      "Failed to retrieve flag image url for United Rep. of Tanzania\n",
      "Scraping data for United States of America...220/230\n",
      "Scraping data for Unknown ...221/230\n",
      "Scraping data for Uruguay...222/230\n",
      "Scraping data for Uzbekistan...223/230\n",
      "Scraping data for Vanuatu...224/230\n",
      "Scraping data for Venezuela (Bolivarian Republic of)...225/230\n",
      "Request for page ID failed\n",
      "Failed to retrieve capital city data for Venezuela (Bolivarian Republic of)\n",
      "Failed to retrieve flag image url for Venezuela (Bolivarian Republic of)\n",
      "Scraping data for Viet Nam...226/230\n",
      "Scraping data for Western Sahara...227/230\n",
      "Scraping data for Yemen...228/230\n",
      "Scraping data for Zambia...229/230\n",
      "Scraping data for Zimbabwe...230/230\n"
     ]
    }
   ],
   "source": [
    "# Function used to scrape data for all countries in UNHCR database\n",
    "def scrape_all_countries():\n",
    "  country_data = []\n",
    "  # Retrieve list of countries\n",
    "  countries = get_all_countries()\n",
    "  count = 1\n",
    "  # Iterate through each country and scrape data\n",
    "  for country in countries:\n",
    "    print(f\"Scraping data for {country['name']}...{count}/{len(countries)}\")\n",
    "    country_code = country[\"iso3\"]\n",
    "    if country_code != None:\n",
    "      data = scrape_country_data(country[\"iso3\"])\n",
    "      if data is not None:\n",
    "        # Data was successfully scraped, add to list\n",
    "        country_data.append(data)\n",
    "    count += 1\n",
    "    time.sleep(5)\n",
    "  return country_data\n",
    "  \n",
    "data = scrape_all_countries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "# Function to write scraped data to JSON file\n",
    "def write_to_json(data):\n",
    "  # Write scraped data to JSON file\n",
    "  with open(json_file_path, \"w\") as outfile:\n",
    "    json.dump(data, outfile, indent=2)\n",
    "\n",
    "print(len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
